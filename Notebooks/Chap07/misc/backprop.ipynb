{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for parameter 0: 0.09284305572509766\n",
      "Gradient for parameter 1: -0.1896030455827713\n",
      "Gradient for parameter 2: 0.04433836042881012\n",
      "Gradient for parameter 3: 0.058229852467775345\n",
      "Gradient for parameter 4: 0.9315991401672363\n",
      "Gradient for parameter 5: 0.2435024380683899\n",
      "Epoch 0, Loss: 1.2287806272506714\n",
      "Epoch 10, Loss: 1.1466872692108154\n",
      "Epoch 20, Loss: 1.0903394222259521\n",
      "Epoch 30, Loss: 1.0514551401138306\n",
      "Epoch 40, Loss: 1.0244476795196533\n",
      "Epoch 50, Loss: 1.0055450201034546\n",
      "Epoch 60, Loss: 0.9921976327896118\n",
      "Epoch 70, Loss: 0.9826788306236267\n",
      "Epoch 80, Loss: 0.9758155345916748\n",
      "Epoch 90, Loss: 0.9708074331283569\n",
      "Epoch 100, Loss: 0.9671062231063843\n",
      "Epoch 110, Loss: 0.9643340110778809\n",
      "Epoch 120, Loss: 0.962228536605835\n",
      "Epoch 130, Loss: 0.9606065154075623\n",
      "Epoch 140, Loss: 0.9593387842178345\n",
      "Epoch 150, Loss: 0.9583333730697632\n",
      "Epoch 160, Loss: 0.9575241208076477\n",
      "Epoch 170, Loss: 0.9568633437156677\n",
      "Epoch 180, Loss: 0.9563159346580505\n",
      "Epoch 190, Loss: 0.9558557271957397\n",
      "Epoch 200, Loss: 0.9554633498191833\n",
      "Epoch 210, Loss: 0.9551240801811218\n",
      "Epoch 220, Loss: 0.9548265933990479\n",
      "Epoch 230, Loss: 0.9545623660087585\n",
      "Epoch 240, Loss: 0.9543247222900391\n",
      "Epoch 250, Loss: 0.9541082978248596\n",
      "Epoch 260, Loss: 0.9539089202880859\n",
      "Epoch 270, Loss: 0.9537234306335449\n",
      "Epoch 280, Loss: 0.9535490274429321\n",
      "Epoch 290, Loss: 0.9533839225769043\n",
      "Epoch 300, Loss: 0.9532263278961182\n",
      "Epoch 310, Loss: 0.9530748724937439\n",
      "Epoch 320, Loss: 0.9529284834861755\n",
      "Epoch 330, Loss: 0.9527862668037415\n",
      "Epoch 340, Loss: 0.9526476263999939\n",
      "Epoch 350, Loss: 0.9525119066238403\n",
      "Epoch 360, Loss: 0.9523786902427673\n",
      "Epoch 370, Loss: 0.9522476196289062\n",
      "Epoch 380, Loss: 0.9521182775497437\n",
      "Epoch 390, Loss: 0.9519906044006348\n",
      "Epoch 400, Loss: 0.9518643021583557\n",
      "Epoch 410, Loss: 0.9517391324043274\n",
      "Epoch 420, Loss: 0.9516151547431946\n",
      "Epoch 430, Loss: 0.9514920711517334\n",
      "Epoch 440, Loss: 0.9513698816299438\n",
      "Epoch 450, Loss: 0.9512484669685364\n",
      "Epoch 460, Loss: 0.9511279463768005\n",
      "Epoch 470, Loss: 0.9510080218315125\n",
      "Epoch 480, Loss: 0.9508887529373169\n",
      "Epoch 490, Loss: 0.9507702589035034\n",
      "Epoch 500, Loss: 0.9506521821022034\n",
      "Epoch 510, Loss: 0.9505348801612854\n",
      "Epoch 520, Loss: 0.9504181146621704\n",
      "Epoch 530, Loss: 0.9503018260002136\n",
      "Epoch 540, Loss: 0.950186014175415\n",
      "Epoch 550, Loss: 0.950070858001709\n",
      "Epoch 560, Loss: 0.9499561190605164\n",
      "Epoch 570, Loss: 0.9498417377471924\n",
      "Epoch 580, Loss: 0.9497279524803162\n",
      "Epoch 590, Loss: 0.9496147632598877\n",
      "Epoch 600, Loss: 0.9495019316673279\n",
      "Epoch 610, Loss: 0.9493895173072815\n",
      "Epoch 620, Loss: 0.9492775201797485\n",
      "Epoch 630, Loss: 0.9491660594940186\n",
      "Epoch 640, Loss: 0.9490548968315125\n",
      "Epoch 650, Loss: 0.9489441514015198\n",
      "Epoch 660, Loss: 0.9488339424133301\n",
      "Epoch 670, Loss: 0.9487239122390747\n",
      "Epoch 680, Loss: 0.9486144781112671\n",
      "Epoch 690, Loss: 0.9485052227973938\n",
      "Epoch 700, Loss: 0.9483965039253235\n",
      "Epoch 710, Loss: 0.9482881426811218\n",
      "Epoch 720, Loss: 0.9481800198554993\n",
      "Epoch 730, Loss: 0.9480722546577454\n",
      "Epoch 740, Loss: 0.9479649066925049\n",
      "Epoch 750, Loss: 0.9478577971458435\n",
      "Epoch 760, Loss: 0.9477512240409851\n",
      "Epoch 770, Loss: 0.9476448893547058\n",
      "Epoch 780, Loss: 0.9475389122962952\n",
      "Epoch 790, Loss: 0.9474329948425293\n",
      "Epoch 800, Loss: 0.9473275542259216\n",
      "Epoch 810, Loss: 0.9472226500511169\n",
      "Epoch 820, Loss: 0.9471179246902466\n",
      "Epoch 830, Loss: 0.9470133781433105\n",
      "Epoch 840, Loss: 0.9469092488288879\n",
      "Epoch 850, Loss: 0.9468054175376892\n",
      "Epoch 860, Loss: 0.9467018246650696\n",
      "Epoch 870, Loss: 0.9465985894203186\n",
      "Epoch 880, Loss: 0.946495771408081\n",
      "Epoch 890, Loss: 0.9463930726051331\n",
      "Epoch 900, Loss: 0.9462907314300537\n",
      "Epoch 910, Loss: 0.946188747882843\n",
      "Epoch 920, Loss: 0.9460869431495667\n",
      "Epoch 930, Loss: 0.9459854960441589\n",
      "Epoch 940, Loss: 0.9458844661712646\n",
      "Epoch 950, Loss: 0.9457836151123047\n",
      "Epoch 960, Loss: 0.9456832408905029\n",
      "Epoch 970, Loss: 0.9455831050872803\n",
      "Epoch 980, Loss: 0.9454832673072815\n",
      "Epoch 990, Loss: 0.9453836679458618\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimplifiedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimplifiedModel, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(1)) for _ in range(6)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        β0, ω0, β1, ω1, β2, ω2 = self.params\n",
    "        return β2 + ω2 * torch.sin(β1 + ω1 * torch.sin(β0 + ω0 * x))\n",
    "\n",
    "# Create model and data\n",
    "model = SimplifiedModel()\n",
    "x = torch.randn(100, 1)\n",
    "y = torch.randn(100, 1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    # Forward pass\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # Backward pass (both #1 and #2 are handled internally)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Print gradients\n",
    "    if epoch == 0:\n",
    "        for i, param in enumerate(model.parameters()):\n",
    "            print(f'Gradient for parameter {i}: {param.grad.item()}')\n",
    "    \n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∂f/∂β: 1.0\n",
      "∂f/∂ω: 4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define a simple layer\n",
    "def layer(β, ω, h):\n",
    "    return β + ω * h\n",
    "\n",
    "# Create some example parameters and input\n",
    "β = torch.tensor([2.0], requires_grad=True)\n",
    "ω = torch.tensor([3.0], requires_grad=True)\n",
    "h = torch.tensor([4.0])\n",
    "\n",
    "# Compute the layer output\n",
    "f = layer(β, ω, h)\n",
    "\n",
    "# Compute gradients\n",
    "f.backward()\n",
    "\n",
    "print(f\"∂f/∂β: {β.grad.item()}\")  # Should be 1\n",
    "print(f\"∂f/∂ω: {ω.grad.item()}\")  # Should be 4 (which is h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Loss: 5.7670\n",
      "Gradient for layer1.weight: 1.2104\n",
      "Gradient for layer1.bias: 0.3221\n",
      "Gradient for layer2.weight: -1.2783\n",
      "Gradient for layer2.bias: -3.9672\n",
      "\n",
      "Epoch 100:\n",
      "Loss: 1.7621\n",
      "Gradient for layer1.weight: -0.0438\n",
      "Gradient for layer1.bias: -0.0295\n",
      "Gradient for layer2.weight: -0.0730\n",
      "Gradient for layer2.bias: -0.3772\n",
      "\n",
      "Epoch 200:\n",
      "Loss: 1.6288\n",
      "Gradient for layer1.weight: -0.0172\n",
      "Gradient for layer1.bias: -0.0327\n",
      "Gradient for layer2.weight: -0.0587\n",
      "Gradient for layer2.bias: 0.0190\n",
      "\n",
      "Epoch 300:\n",
      "Loss: 1.5363\n",
      "Gradient for layer1.weight: 0.0002\n",
      "Gradient for layer1.bias: -0.0243\n",
      "Gradient for layer2.weight: -0.0466\n",
      "Gradient for layer2.bias: 0.0843\n",
      "\n",
      "Epoch 400:\n",
      "Loss: 1.5053\n",
      "Gradient for layer1.weight: 0.0068\n",
      "Gradient for layer1.bias: -0.0180\n",
      "Gradient for layer2.weight: -0.0261\n",
      "Gradient for layer2.bias: 0.0557\n",
      "\n",
      "Epoch 500:\n",
      "Loss: 1.4922\n",
      "Gradient for layer1.weight: -0.0045\n",
      "Gradient for layer1.bias: -0.0165\n",
      "Gradient for layer2.weight: -0.0121\n",
      "Gradient for layer2.bias: 0.0348\n",
      "\n",
      "Epoch 600:\n",
      "Loss: 1.4858\n",
      "Gradient for layer1.weight: -0.0013\n",
      "Gradient for layer1.bias: -0.0132\n",
      "Gradient for layer2.weight: -0.0034\n",
      "Gradient for layer2.bias: 0.0211\n",
      "\n",
      "Epoch 700:\n",
      "Loss: 1.4811\n",
      "Gradient for layer1.weight: -0.0002\n",
      "Gradient for layer1.bias: -0.0121\n",
      "Gradient for layer2.weight: 0.0017\n",
      "Gradient for layer2.bias: 0.0112\n",
      "\n",
      "Epoch 800:\n",
      "Loss: 1.4760\n",
      "Gradient for layer1.weight: -0.0006\n",
      "Gradient for layer1.bias: -0.0125\n",
      "Gradient for layer2.weight: 0.0047\n",
      "Gradient for layer2.bias: 0.0051\n",
      "\n",
      "Epoch 900:\n",
      "Loss: 1.4699\n",
      "Gradient for layer1.weight: -0.0009\n",
      "Gradient for layer1.bias: -0.0135\n",
      "Gradient for layer2.weight: 0.0066\n",
      "Gradient for layer2.bias: 0.0020\n",
      "\n",
      "Final layer1.weight mean: -0.2455\n",
      "Final layer1.bias mean: 0.4839\n",
      "Final layer2.weight mean: 0.2279\n",
      "Final layer2.bias mean: 1.0243\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(1, 5)\n",
    "        self.layer2 = nn.Linear(5, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        return self.layer2(x)\n",
    "\n",
    "# Create model and data\n",
    "model = TwoLayerNet()\n",
    "x = torch.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y_true = 2 * torch.sin(x) + 1 + 0.1 * torch.randn(x.shape)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    # Forward pass\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y_true)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Print gradients every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}:')\n",
    "        print(f'Loss: {loss.item():.4f}')\n",
    "        for name, param in model.named_parameters():\n",
    "            print(f'Gradient for {name}: {param.grad.mean().item():.4f}')\n",
    "        print()\n",
    "    \n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "# Print final parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'Final {name} mean: {param.mean().item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
